diff --git a/node_modules/bert-tokenizer/dist/index.js b/node_modules/bert-tokenizer/dist/index.js
index 58ef9c4..9519749 100644
--- a/node_modules/bert-tokenizer/dist/index.js
+++ b/node_modules/bert-tokenizer/dist/index.js
@@ -3,9 +3,10 @@ var __importDefault = (this && this.__importDefault) || function (mod) {
     return (mod && mod.__esModule) ? mod : { "default": mod };
 };
 Object.defineProperty(exports, "__esModule", { value: true });
-var path_1 = require("path");
+//var path_1 = require("path");
 var wordpiecetokenizer_1 = __importDefault(require("./wordpiecetokenizer"));
-var DEFAUT_VOCAB_PATH = path_1.join(__dirname, '..', 'assets', 'vocab.json');
+//var DEFAUT_VOCAB_PATH = path_1.join(__dirname, '..', 'assets', 'vocab.json');
+var DEFAUT_VOCAB_PATH = ""
 function isPunctuation(cp) {
     return (punctuations.indexOf(cp) !== -1);
 }
diff --git a/node_modules/bert-tokenizer/dist/wordpiecetokenizer.js b/node_modules/bert-tokenizer/dist/wordpiecetokenizer.js
index a8a60d6..3aff60f 100644
--- a/node_modules/bert-tokenizer/dist/wordpiecetokenizer.js
+++ b/node_modules/bert-tokenizer/dist/wordpiecetokenizer.js
@@ -7,7 +7,7 @@ var __importStar = (this && this.__importStar) || function (mod) {
     return result;
 };
 Object.defineProperty(exports, "__esModule", { value: true });
-var fs = __importStar(require("fs"));
+//var fs = __importStar(require("fs"));
 var TrieNode = (function () {
     function TrieNode(key) {
         this.key = key;
@@ -69,7 +69,7 @@ var WordPieceTokenizer = (function () {
         this.UNK_INDEX = 100;
     }
     WordPieceTokenizer.prototype.load = function (vocabUrl) {
-        this.vocab = this.loadVocab(vocabUrl);
+        this.vocab = require('../assets/vocab.json')
         this.trie = new Trie();
         this.trie.insert('[CLS]', 1, 101);
         this.trie.insert('[SEP]', 1, 102);
@@ -79,7 +79,7 @@ var WordPieceTokenizer = (function () {
         }
     };
     WordPieceTokenizer.prototype.loadVocab = function (vocabUrl) {
-        var json = fs.readFileSync(vocabUrl, 'utf-8');
+        //var json = fs.readFileSync(vocabUrl, 'utf-8');
         return JSON.parse(json);
     };
     WordPieceTokenizer.prototype.processInput = function (text) {
diff --git a/node_modules/bert-tokenizer/tsconfig.json b/node_modules/bert-tokenizer/tsconfig.json
index f899f21..bea80b2 100644
--- a/node_modules/bert-tokenizer/tsconfig.json
+++ b/node_modules/bert-tokenizer/tsconfig.json
@@ -9,7 +9,7 @@
     "declaration": true,
     "target": "es5",
     "lib": ["es2015", "dom"],
-    "outDir": "./dist",
+    //"outDir": "./dist",
     "noUnusedLocals": true,
     "noImplicitReturns": true,
     "noImplicitThis": true,
@@ -21,5 +21,5 @@
     "experimentalDecorators": true,
     "esModuleInterop": true
   },
-  "include": ["src/**/*"]
+  "include": ["dist/**/*"]
 }
